
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Crawling Berita Online &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'berita-online';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Markdown Files" href="markdown.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="My sample book - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="My sample book - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to your Jupyter Book
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="markdown.html">Markdown Files</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Crawling Berita Online</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fberita-online.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/berita-online.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Crawling Berita Online</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#konsep-crawling-data">Konsep Crawling Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#teknik-dan-cara-crawling-menggunakan-python">Teknik dan Cara Crawling Menggunakan Python</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tools-yang-digunakan-lybrary">Tools yang Digunakan (Lybrary)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#code-crawling-berita-online">Code Crawling Berita Online</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="crawling-berita-online">
<h1>Crawling Berita Online<a class="headerlink" href="#crawling-berita-online" title="Link to this heading">#</a></h1>
<section id="konsep-crawling-data">
<h2>Konsep Crawling Data<a class="headerlink" href="#konsep-crawling-data" title="Link to this heading">#</a></h2>
<p>Crawling data adalah proses otomatis di mana sebuah program komputer (disebut “crawler” atau “spider”) menjelajahi internet untuk mengumpulkan informasi dari berbagai situs web. Bayangkan seperti laba-laba yang berjalan di seluruh jaring untuk menemukan dan mengumpulkan informasi. Crawler ini biasanya digunakan untuk mengindeks halaman web, sehingga informasi tersebut dapat dicari dan diakses dengan mudah, seperti yang dilakukan oleh mesin pencari seperti Google.</p>
<p>Crawling digunakan untuk mengumpulkan data dari berbagai sumber web untuk analisis, pelatihan model machine learning, atau keperluan riset. Mesin pencari seperti Google menggunakan crawler untuk mengindeks halaman web sehingga dapat ditampilkan dalam hasil pencarian, dan Beberapa perusahaan menggunakan crawling untuk memantau harga produk, berita, atau ulasan secara real-time.</p>
</section>
<section id="teknik-dan-cara-crawling-menggunakan-python">
<h2>Teknik dan Cara Crawling Menggunakan Python<a class="headerlink" href="#teknik-dan-cara-crawling-menggunakan-python" title="Link to this heading">#</a></h2>
<p>Crawling data dengan Python adalah proses mengambil data dari situs web secara otomatis dengan menggunakan alat dan pustaka tertentu. Berikut adalah penjelasan langkah-langkahnya:</p>
<ol class="arabic simple">
<li><p>Persiapan Lingkungan (Instalasi Pustaka Python) : menginstal beberapa pustaka Python yang digunakan untuk mengakses dan memanipulasi data web. Pustaka utama yang biasanya digunakan meliputi:</p></li>
</ol>
<ul class="simple">
<li><p>Requests: Untuk mengirim permintaan HTTP ke situs web dan mengambil halaman web sebagai respons.</p></li>
<li><p>BeautifulSoup: Untuk mem-parsing dan mengekstrak data dari konten HTML yang didapatkan dari situs web.</p></li>
<li><p>Scrapy: Sebuah framework yang lebih canggih yang dirancang khusus untuk crawling data dalam skala besar.</p></li>
<li><p>Selenium: Digunakan untuk situs web yang menggunakan JavaScript, di mana berinteraksi dengan elemen web yang dinamis.</p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p>Mengirim Permintaan HTTP : Langkah pertama dalam crawling adalah mengirimkan permintaan ke situs web target menggunakan metode HTTP, seperti GET. Hal ini memungkinkan untuk mendapatkan konten halaman web yang kemudian dapat diolah lebih lanjut.</p></li>
<li><p>Parsing HTML
Setelah menerima respons dari situs web, akan mendapatkan konten HTML dari halaman tersebut. HTML ini perlu diurai untuk mengekstrak informasi yang relevan seperti teks, gambar, link, atau data lain yang diinginkan.
Pustaka seperti BeautifulSoup memungkinkan untuk mengurai struktur HTML dan menavigasi melalui elemen-elemen di dalamnya, seperti tag div, a, p, dan lainnya, untuk menemukan data yang dibutuhkan.</p></li>
<li><p>Mengatasi Halaman Web Dinamis
Beberapa situs web tidak menampilkan konten secara langsung dalam HTML, melainkan menggunakan JavaScript untuk memuat data secara dinamis. Untuk meng-crawl data dari situs semacam ini, perlu menggunakan alat seperti Selenium, yang dapat mengotomatiskan browser web untuk berinteraksi dengan elemen halaman (seperti klik tombol atau mengisi formulir) dan mengambil data setelah halaman sepenuhnya dimuat.</p></li>
<li><p>Framework Scrapy
Untuk crawling yang lebih kompleks dan dalam skala besar, Scrapy merupakan pilihan yang tepat. Framework ini memungkinkan untuk mengelola seluruh proses crawling, mulai dari mengirim permintaan, mengolah data, hingga menyimpannya dalam berbagai format. Scrapy juga mendukung fitur seperti crawling paralel, pengaturan ulang URL yang akan dikunjungi, dan middleware untuk menyesuaikan perilaku crawler.</p></li>
<li><p>Pengaturan Batasan dan Kepatuhan
Dalam melakukan crawling, penting untuk memperhatikan beberapa batasan agar tidak membebani server situs web yang ditargetkan. Ini termasuk mengatur interval waktu antara permintaan dan mematuhi aturan yang ditetapkan oleh situs dalam file robots.txt, yang mengatur halaman mana yang boleh di-crawl dan mana yang tidak.</p></li>
<li><p>Penyimpanan Data
Setelah data diekstraksi dari situs web, langkah berikutnya adalah menyimpannya. Data ini bisa disimpan dalam berbagai format seperti CSV, JSON, atau langsung dimasukkan ke dalam database. Penyimpanan ini memungkinkan untuk menganalisis data lebih lanjut atau menggunakannya untuk tujuan lain.</p></li>
<li><p>Pemantauan dan Pemeliharaan
Proses crawling perlu dipantau untuk memastikan bahwa tidak ada masalah yang muncul, seperti situs web yang mengubah struktur HTML mereka. Pemeliharaan rutin mungkin diperlukan untuk memperbarui crawler agar tetap efektif dalam mengumpulkan data.
Dengan memahami dan menerapkan langkah-langkah ini, dapat melakukan crawling data menggunakan Python dengan cara yang efisien dan sesuai dengan praktik terbaik.</p></li>
</ol>
</section>
<section id="tools-yang-digunakan-lybrary">
<h2>Tools yang Digunakan (Lybrary)<a class="headerlink" href="#tools-yang-digunakan-lybrary" title="Link to this heading">#</a></h2>
<p>Dalam proses crawling data menggunakan Python, beberapa pustaka (library) utama sering digunakan. Berikut adalah pustaka-pustaka tersebut beserta fungsinya:</p>
<ol class="arabic simple">
<li><p>Requests</p></li>
</ol>
<p>Fungsi: Mengirimkan permintaan HTTP ke situs web untuk mendapatkan data.
Kegunaan: Mengambil konten halaman web seperti HTML, JSON, atau file lainnya.</p>
<ol class="arabic simple" start="2">
<li><p>BeautifulSoup (bs4)</p></li>
</ol>
<p>Fungsi: Mem-parsing HTML dan XML untuk mengekstrak informasi.
Kegunaan: Menavigasi dan mencari elemen dalam struktur HTML, seperti tag div, a, p, dll., untuk mendapatkan data yang diinginkan.</p>
<ol class="arabic simple" start="3">
<li><p>Scrapy</p></li>
</ol>
<p>Fungsi: Framework komprehensif untuk crawling dan scraping data web.
Kegunaan: Mengelola seluruh proses crawling termasuk pengiriman permintaan, parsing data, dan penyimpanan hasil. Mendukung fitur seperti pengaturan concurrency, pengelolaan antrian URL, dan pengolahan middleware.</p>
<ol class="arabic simple" start="4">
<li><p>Selenium</p></li>
</ol>
<p>Fungsi: Mengotomatiskan interaksi dengan browser web.
Kegunaan: Cocok untuk situs web dinamis yang memerlukan interaksi pengguna, seperti klik tombol, pengisian formulir, atau berinteraksi dengan elemen yang dimuat dengan JavaScript.
5. Pandas</p>
<p>Fungsi: Memanipulasi dan menganalisis data dalam format tabular.
Kegunaan: Setelah data diambil, Pandas dapat digunakan untuk membersihkan, mengolah, dan menganalisis data sebelum menyimpannya dalam format seperti CSV atau Excel.
6. BeautifulSoup4</p>
<p>Fungsi: Memparsing dan mengekstrak data dari halaman web.
Kegunaan: Mirip dengan BeautifulSoup, sering digunakan untuk proses ekstraksi data</p>
</section>
<section id="code-crawling-berita-online">
<h2>Code Crawling Berita Online<a class="headerlink" href="#code-crawling-berita-online" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Meng-import Library yang Dibutuhkan</p></li>
</ol>
<ul class="simple">
<li><p>requests: untuk mengirim permintaan HTTP ke server dan mendapatkan respons.</p></li>
<li><p>BeautifulSoup dari bs4: untuk mem-parsing HTML dan mengekstrak informasi dari halaman web.</p></li>
<li><p>pandas: untuk mengelola dan memanipulasi data dalam bentuk DataFrame.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</pre></div>
</div>
</div>
</div>
<ol class="arabic simple" start="2">
<li><p>Menentukan URL Awal</p></li>
</ol>
<p>base_url menyimpan URL halaman web utama yang akan di-crawl, dalam hal ini adalah halaman politik dari situs Times Indonesia.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># URL awal</span>
<span class="n">base_url</span> <span class="o">=</span> <span class="s1">&#39;https://timesindonesia.co.id/kanal/politik&#39;</span>
</pre></div>
</div>
</div>
</div>
<ol class="arabic simple" start="3">
<li><p>Fungsi untuk Mengambil Konten Berita dari Link Detail</p></li>
</ol>
<p>Fungsi get_content(news_url) digunakan untuk mengambil isi berita dari halaman detail. Fungsi ini melakukan hal berikut:</p>
<ul class="simple">
<li><p>Mengirim permintaan GET ke news_url.</p></li>
<li><p>Memparsing konten HTML respons menggunakan BeautifulSoup.</p></li>
<li><p>Mencari div dengan id=”news_content” yang diharapkan berisi teks berita.</p></li>
<li><p>Mengembalikan teks yang telah di-strip jika ditemukan, atau mengembalikan string kosong jika tidak ditemukan.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Fungsi untuk mengambil konten berita dari link detail</span>
<span class="k">def</span> <span class="nf">get_content</span><span class="p">(</span><span class="n">news_url</span><span class="p">):</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">news_url</span><span class="p">)</span>
    <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="s1">&#39;html.parser&#39;</span><span class="p">)</span>
    <span class="n">content_div</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;div&#39;</span><span class="p">,</span> <span class="nb">id</span><span class="o">=</span><span class="s1">&#39;news_content&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">content_div</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">content_div</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
    <span class="k">return</span> <span class="s2">&quot;&quot;</span>
</pre></div>
</div>
</div>
</div>
<ol class="arabic simple" start="4">
<li><p>Membuat List untuk Menyimpan Data</p></li>
</ol>
<p>List data dibuat untuk menyimpan informasi dari setiap artikel berita yang akan diambil.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># List untuk menyimpan data</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>
</pre></div>
</div>
</div>
</div>
<ol class="arabic simple" start="5">
<li><p>Looping untuk Mengambil 50 Berita Pertama</p></li>
</ol>
<p>Looping ini bertujuan untuk terus mengambil data dari halaman web hingga jumlah berita yang terkumpul mencapai 50 berita dari kanal politik.</p>
<ol class="arabic simple">
<li><p>Looping Utama:</p></li>
</ol>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>- Variabel page diinisialisasi dengan nilai 1, yang mewakili halaman pertama.
- Looping while len(data) &lt; 50: akan terus berjalan selama jumlah berita yang terkumpul di dalam list data belum mencapai 50.
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p>Mengambil Konten Setiap Halaman:
- Dalam setiap iterasi, program mengirimkan permintaan GET ke URL halaman yang sesuai dengan page saat ini.
- Konten HTML dari respons tersebut kemudian diparsing menggunakan BeautifulSoup.</p></li>
<li><p>Mengidentifikasi dan Mengekstrak Artikel:</p></li>
</ol>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>- Semua artikel berita pada halaman tersebut diidentifikasi dengan mencari elemen div yang memiliki kelas media-body.
- Looping for article in articles: digunakan untuk mengiterasi setiap artikel yang ditemukan.
</pre></div>
</div>
<ol class="arabic simple" start="4">
<li><p>Pengambilan dan Penyimpanan Data Artikel:</p></li>
</ol>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>- Untuk setiap artikel, jika list data sudah berisi 50 berita, maka proses looping dihentikan dengan break.
- Selanjutnya, kode mencoba untuk mengekstrak judul berita, tanggal, dan link ke halaman detail artikel dari tag HTML yang sesuai.
- Jika semua elemen yang dibutuhkan (judul, tanggal, link) ditemukan, data tersebut diproses lebih lanjut.
- Isi berita diambil dengan memanggil fungsi get_content(link).
- Data dari artikel tersebut kemudian disimpan dalam list data sebagai dictionary.
</pre></div>
</div>
<ol class="arabic simple" start="5">
<li><p>Pindah ke Halaman Berikutnya:</p></li>
</ol>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>- Setelah semua artikel pada halaman saat ini selesai diproses, variabel page ditingkatkan (page += 1) untuk melanjutkan ke halaman berikutnya dalam iterasi berikutnya.
- Proses ini terus berjalan hingga list data berisi 50 berita, di mana proses looping akan berhenti.
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Looping untuk 50 berita pertama</span>
<span class="n">page</span> <span class="o">=</span> <span class="mi">1</span>
<span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">50</span><span class="p">:</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">base_url</span> <span class="o">+</span> <span class="sa">f</span><span class="s1">&#39;?page=</span><span class="si">{</span><span class="n">page</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="s1">&#39;html.parser&#39;</span><span class="p">)</span>

    <span class="n">articles</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s1">&#39;div&#39;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s1">&#39;media-body&#39;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">article</span> <span class="ow">in</span> <span class="n">articles</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">50</span><span class="p">:</span>
            <span class="k">break</span>
        <span class="c1"># Mengambil data dari tag yang sesuai</span>
        <span class="n">title_tag</span> <span class="o">=</span> <span class="n">article</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;h2&#39;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s1">&#39;h6 mt-0 mb-1&#39;</span><span class="p">)</span>
        <span class="n">date_tag</span> <span class="o">=</span> <span class="n">article</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;small&#39;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s1">&#39;text-muted&#39;</span><span class="p">)</span>
        <span class="n">link_tag</span> <span class="o">=</span> <span class="n">article</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s1">&#39;text-light stretched-link&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">title_tag</span> <span class="ow">and</span> <span class="n">date_tag</span> <span class="ow">and</span> <span class="n">link_tag</span><span class="p">:</span>
            <span class="n">title</span> <span class="o">=</span> <span class="n">title_tag</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="n">date</span> <span class="o">=</span> <span class="n">date_tag</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="n">category</span> <span class="o">=</span> <span class="s2">&quot;Politik&quot;</span>  <span class="c1"># Kategori tetap karena berasal dari kanal Politik</span>
            <span class="n">link</span> <span class="o">=</span> <span class="s1">&#39;https://timesindonesia.co.id&#39;</span> <span class="o">+</span> <span class="n">link_tag</span><span class="p">[</span><span class="s1">&#39;href&#39;</span><span class="p">]</span>
            <span class="n">content</span> <span class="o">=</span> <span class="n">get_content</span><span class="p">(</span><span class="n">link</span><span class="p">)</span>

            <span class="c1"># Menyimpan data dalam dictionary</span>
            <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s1">&#39;judul_berita&#39;</span><span class="p">:</span> <span class="n">title</span><span class="p">,</span>
                <span class="s1">&#39;isi_berita&#39;</span><span class="p">:</span> <span class="n">content</span><span class="p">,</span>
                <span class="s1">&#39;tanggal_berita&#39;</span><span class="p">:</span> <span class="n">date</span><span class="p">,</span>
                <span class="s1">&#39;kategori_berita&#39;</span><span class="p">:</span> <span class="n">category</span>
            <span class="p">})</span>

    <span class="n">page</span> <span class="o">+=</span> <span class="mi">1</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="nn">&lt;ipython-input-5-5020171a9013&gt;</span> in <span class="ni">&lt;cell line: 3&gt;</span><span class="nt">()</span>
<span class="g g-Whitespace">     </span><span class="mi">20</span>             <span class="n">category</span> <span class="o">=</span> <span class="s2">&quot;Politik&quot;</span>  <span class="c1"># Kategori tetap karena berasal dari kanal Politik</span>
<span class="g g-Whitespace">     </span><span class="mi">21</span>             <span class="n">link</span> <span class="o">=</span> <span class="s1">&#39;https://timesindonesia.co.id&#39;</span> <span class="o">+</span> <span class="n">link_tag</span><span class="p">[</span><span class="s1">&#39;href&#39;</span><span class="p">]</span>
<span class="ne">---&gt; </span><span class="mi">22</span>             <span class="n">content</span> <span class="o">=</span> <span class="n">get_content</span><span class="p">(</span><span class="n">link</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">23</span> 
<span class="g g-Whitespace">     </span><span class="mi">24</span>             <span class="c1"># Menyimpan data dalam dictionary</span>

<span class="nn">&lt;ipython-input-3-0611e7a7d08c&gt;</span> in <span class="ni">get_content</span><span class="nt">(news_url)</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="c1"># Fungsi untuk mengambil konten berita dari link detail</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="k">def</span> <span class="nf">get_content</span><span class="p">(</span><span class="n">news_url</span><span class="p">):</span>
<span class="ne">----&gt; </span><span class="mi">3</span>     <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">news_url</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span>     <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="s1">&#39;html.parser&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span>     <span class="n">content_div</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;div&#39;</span><span class="p">,</span> <span class="nb">id</span><span class="o">=</span><span class="s1">&#39;news_content&#39;</span><span class="p">)</span>

<span class="nn">/usr/local/lib/python3.10/dist-packages/requests/api.py</span> in <span class="ni">get</span><span class="nt">(url, params, **kwargs)</span>
<span class="g g-Whitespace">     </span><span class="mi">71</span>     <span class="s2">&quot;&quot;&quot;</span>
<span class="g g-Whitespace">     </span><span class="mi">72</span><span class="s2"> </span>
<span class="ne">---&gt; </span><span class="mi">73</span><span class="s2">     return request(&quot;get&quot;, url, params=params, **kwargs)</span>
<span class="g g-Whitespace">     </span><span class="mi">74</span><span class="s2"> </span>
<span class="g g-Whitespace">     </span><span class="mi">75</span><span class="s2"> </span>

<span class="nn">/usr/local/lib/python3.10/dist-packages/requests/api.py</span> in <span class="ni">request</span><span class="nt">(method, url, **kwargs)</span>
<span class="g g-Whitespace">     </span><span class="mi">57</span><span class="s2">     # cases, and look like a memory leak in others.</span>
<span class="g g-Whitespace">     </span><span class="mi">58</span><span class="s2">     with sessions.Session() as session:</span>
<span class="ne">---&gt; </span><span class="mi">59</span><span class="s2">         return session.request(method=method, url=url, **kwargs)</span>
<span class="g g-Whitespace">     </span><span class="mi">60</span><span class="s2"> </span>
<span class="g g-Whitespace">     </span><span class="mi">61</span><span class="s2"> </span>

<span class="nn">/usr/local/lib/python3.10/dist-packages/requests/sessions.py</span> in <span class="ni">request</span><span class="nt">(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)</span>
<span class="g g-Whitespace">    </span><span class="mi">587</span><span class="s2">         }</span>
<span class="g g-Whitespace">    </span><span class="mi">588</span><span class="s2">         send_kwargs.update(settings)</span>
<span class="ne">--&gt; </span><span class="mi">589</span><span class="s2">         resp = self.send(prep, **send_kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">590</span><span class="s2"> </span>
<span class="g g-Whitespace">    </span><span class="mi">591</span><span class="s2">         return resp</span>

<span class="nn">/usr/local/lib/python3.10/dist-packages/requests/sessions.py</span> in <span class="ni">send</span><span class="nt">(self, request, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">701</span><span class="s2"> </span>
<span class="g g-Whitespace">    </span><span class="mi">702</span><span class="s2">         # Send the request</span>
<span class="ne">--&gt; </span><span class="mi">703</span><span class="s2">         r = adapter.send(request, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">704</span><span class="s2"> </span>
<span class="g g-Whitespace">    </span><span class="mi">705</span><span class="s2">         # Total elapsed time of the request (approximately)</span>

<span class="nn">/usr/local/lib/python3.10/dist-packages/requests/adapters.py</span> in <span class="ni">send</span><span class="nt">(self, request, stream, timeout, verify, cert, proxies)</span>
<span class="g g-Whitespace">    </span><span class="mi">665</span><span class="s2"> </span>
<span class="g g-Whitespace">    </span><span class="mi">666</span><span class="s2">         try:</span>
<span class="ne">--&gt; </span><span class="mi">667</span><span class="s2">             resp = conn.urlopen(</span>
<span class="g g-Whitespace">    </span><span class="mi">668</span><span class="s2">                 method=request.method,</span>
<span class="g g-Whitespace">    </span><span class="mi">669</span><span class="s2">                 url=url,</span>

<span class="nn">/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py</span> in <span class="ni">urlopen</span><span class="nt">(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)</span>
<span class="g g-Whitespace">    </span><span class="mi">789</span><span class="s2"> </span>
<span class="g g-Whitespace">    </span><span class="mi">790</span><span class="s2">             # Make the request on the HTTPConnection object</span>
<span class="ne">--&gt; </span><span class="mi">791</span><span class="s2">             response = self._make_request(</span>
<span class="g g-Whitespace">    </span><span class="mi">792</span><span class="s2">                 conn,</span>
<span class="g g-Whitespace">    </span><span class="mi">793</span><span class="s2">                 method,</span>

<span class="nn">/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py</span> in <span class="ni">_make_request</span><span class="nt">(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)</span>
<span class="g g-Whitespace">    </span><span class="mi">535</span><span class="s2">         # Receive the response from the server</span>
<span class="g g-Whitespace">    </span><span class="mi">536</span><span class="s2">         try:</span>
<span class="ne">--&gt; </span><span class="mi">537</span><span class="s2">             response = conn.getresponse()</span>
<span class="g g-Whitespace">    </span><span class="mi">538</span><span class="s2">         except (BaseSSLError, OSError) as e:</span>
<span class="g g-Whitespace">    </span><span class="mi">539</span><span class="s2">             self._raise_timeout(err=e, url=url, timeout_value=read_timeout)</span>

<span class="nn">/usr/local/lib/python3.10/dist-packages/urllib3/connection.py</span> in <span class="ni">getresponse</span><span class="nt">(self)</span>
<span class="g g-Whitespace">    </span><span class="mi">459</span><span class="s2"> </span>
<span class="g g-Whitespace">    </span><span class="mi">460</span><span class="s2">         # Get the response from http.client.HTTPConnection</span>
<span class="ne">--&gt; </span><span class="mi">461</span><span class="s2">         httplib_response = super().getresponse()</span>
<span class="g g-Whitespace">    </span><span class="mi">462</span><span class="s2"> </span>
<span class="g g-Whitespace">    </span><span class="mi">463</span><span class="s2">         try:</span>

<span class="nn">/usr/lib/python3.10/http/client.py</span> in <span class="ni">getresponse</span><span class="nt">(self)</span>
<span class="g g-Whitespace">   </span><span class="mi">1373</span><span class="s2">         try:</span>
<span class="g g-Whitespace">   </span><span class="mi">1374</span><span class="s2">             try:</span>
<span class="ne">-&gt; </span><span class="mi">1375</span><span class="s2">                 response.begin()</span>
<span class="g g-Whitespace">   </span><span class="mi">1376</span><span class="s2">             except ConnectionError:</span>
<span class="g g-Whitespace">   </span><span class="mi">1377</span><span class="s2">                 self.close()</span>

<span class="nn">/usr/lib/python3.10/http/client.py</span> in <span class="ni">begin</span><span class="nt">(self)</span>
<span class="g g-Whitespace">    </span><span class="mi">316</span><span class="s2">         # read until we get a non-100 response</span>
<span class="g g-Whitespace">    </span><span class="mi">317</span><span class="s2">         while True:</span>
<span class="ne">--&gt; </span><span class="mi">318</span><span class="s2">             version, status, reason = self._read_status()</span>
<span class="g g-Whitespace">    </span><span class="mi">319</span><span class="s2">             if status != CONTINUE:</span>
<span class="g g-Whitespace">    </span><span class="mi">320</span><span class="s2">                 break</span>

<span class="nn">/usr/lib/python3.10/http/client.py</span> in <span class="ni">_read_status</span><span class="nt">(self)</span>
<span class="g g-Whitespace">    </span><span class="mi">277</span><span class="s2"> </span>
<span class="g g-Whitespace">    </span><span class="mi">278</span><span class="s2">     def _read_status(self):</span>
<span class="ne">--&gt; </span><span class="mi">279</span><span class="s2">         line = str(self.fp.readline(_MAXLINE + 1), &quot;iso-8859-1&quot;)</span>
<span class="g g-Whitespace">    </span><span class="mi">280</span><span class="s2">         if len(line) &gt; _MAXLINE:</span>
<span class="g g-Whitespace">    </span><span class="mi">281</span><span class="s2">             raise LineTooLong(&quot;status line&quot;)</span>

<span class="nn">/usr/lib/python3.10/socket.py</span> in <span class="ni">readinto</span><span class="nt">(self, b)</span>
<span class="g g-Whitespace">    </span><span class="mi">703</span><span class="s2">         while True:</span>
<span class="g g-Whitespace">    </span><span class="mi">704</span><span class="s2">             try:</span>
<span class="ne">--&gt; </span><span class="mi">705</span><span class="s2">                 return self._sock.recv_into(b)</span>
<span class="g g-Whitespace">    </span><span class="mi">706</span><span class="s2">             except timeout:</span>
<span class="g g-Whitespace">    </span><span class="mi">707</span><span class="s2">                 self._timeout_occurred = True</span>

<span class="nn">/usr/lib/python3.10/ssl.py</span> in <span class="ni">recv_into</span><span class="nt">(self, buffer, nbytes, flags)</span>
<span class="g g-Whitespace">   </span><span class="mi">1301</span><span class="s2">                   &quot;non-zero flags not allowed in calls to recv_into() on </span><span class="si">%s</span><span class="s2">&quot; %</span>
<span class="g g-Whitespace">   </span><span class="mi">1302</span><span class="s2">                   self.__class__)</span>
<span class="ne">-&gt; </span><span class="mi">1303</span><span class="s2">             return self.read(nbytes, buffer)</span>
<span class="g g-Whitespace">   </span><span class="mi">1304</span><span class="s2">         else:</span>
<span class="g g-Whitespace">   </span><span class="mi">1305</span><span class="s2">             return super().recv_into(buffer, nbytes, flags)</span>

<span class="nn">/usr/lib/python3.10/ssl.py</span> in <span class="ni">read</span><span class="nt">(self, len, buffer)</span>
<span class="g g-Whitespace">   </span><span class="mi">1157</span><span class="s2">         try:</span>
<span class="g g-Whitespace">   </span><span class="mi">1158</span><span class="s2">             if buffer is not None:</span>
<span class="ne">-&gt; </span><span class="mi">1159</span><span class="s2">                 return self._sslobj.read(len, buffer)</span>
<span class="g g-Whitespace">   </span><span class="mi">1160</span><span class="s2">             else:</span>
<span class="g g-Whitespace">   </span><span class="mi">1161</span><span class="s2">                 return self._sslobj.read(len)</span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
<ol class="arabic simple" start="6">
<li><p>Mengonversi Data menjadi DataFrame</p></li>
</ol>
<p>Setelah 50 artikel terkumpul, data tersebut dikonversi menjadi DataFrame menggunakan pandas untuk memudahkan manipulasi data lebih lanjut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Mengonversi data menjadi DataFrame</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ol class="arabic simple" start="7">
<li><p>Menyimpan Data ke dalam File CSV</p></li>
</ol>
<p>DataFrame disimpan ke dalam file CSV dengan nama Tugas-Crawling-Data-Berita.csv</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Menyimpan data ke dalam file CSV</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;Tugas-Crawling-Data-Berita.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ol class="arabic simple" start="8">
<li><p>Mencetak Jumlah Artikel yang Berhasil Diambil</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Successfully scraped </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="si">}</span><span class="s1"> articles.&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Successfully scraped 50 articles.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                         judul_berita  \
0   Bacawabup Lathifah Solidkan Seribu Relawan, Si...   
1   Rois Syuriah Sebut Visi Misi Untoro-Wahyudi Se...   
2   Ribuan Kader PKB Kabupaten Mojokerto Panasi Me...   
3   Sejumlah Kader Partai Golkar dan PKB Berbalik ...   
4   Sukiman Azmy Mantapkan Dukungan pada Iqbal-Din...   
5   Menkumham Supratman Teken SK Baru PKB, Duet Ca...   
6   Pengamat: Pilgub Jatim Lebih Dominan Melihat F...   
7   Pilkada Majalengka, Aceng Sunanto Alihkan Duku...   
8   Bacawabup Lathifah Solidkan Seribu Relawan, Si...   
9   Rois Syuriah Sebut Visi Misi Untoro-Wahyudi Se...   
10  Ribuan Kader PKB Kabupaten Mojokerto Panasi Me...   
11  Sejumlah Kader Partai Golkar dan PKB Berbalik ...   
12  Sukiman Azmy Mantapkan Dukungan pada Iqbal-Din...   
13  Menkumham Supratman Teken SK Baru PKB, Duet Ca...   
14  Pengamat: Pilgub Jatim Lebih Dominan Melihat F...   
15  Pilkada Majalengka, Aceng Sunanto Alihkan Duku...   
16  Bacawabup Lathifah Solidkan Seribu Relawan, Si...   
17  Rois Syuriah Sebut Visi Misi Untoro-Wahyudi Se...   
18  Ribuan Kader PKB Kabupaten Mojokerto Panasi Me...   
19  Sejumlah Kader Partai Golkar dan PKB Berbalik ...   
20  Sukiman Azmy Mantapkan Dukungan pada Iqbal-Din...   
21  Menkumham Supratman Teken SK Baru PKB, Duet Ca...   
22  Pengamat: Pilgub Jatim Lebih Dominan Melihat F...   
23  Pilkada Majalengka, Aceng Sunanto Alihkan Duku...   
24  Bacawabup Lathifah Solidkan Seribu Relawan, Si...   
25  Rois Syuriah Sebut Visi Misi Untoro-Wahyudi Se...   
26  Ribuan Kader PKB Kabupaten Mojokerto Panasi Me...   
27  Sejumlah Kader Partai Golkar dan PKB Berbalik ...   
28  Sukiman Azmy Mantapkan Dukungan pada Iqbal-Din...   
29  Menkumham Supratman Teken SK Baru PKB, Duet Ca...   
30  Pengamat: Pilgub Jatim Lebih Dominan Melihat F...   
31  Pilkada Majalengka, Aceng Sunanto Alihkan Duku...   
32  Bacawabup Lathifah Solidkan Seribu Relawan, Si...   
33  Rois Syuriah Sebut Visi Misi Untoro-Wahyudi Se...   
34  Ribuan Kader PKB Kabupaten Mojokerto Panasi Me...   
35  Sejumlah Kader Partai Golkar dan PKB Berbalik ...   
36  Sukiman Azmy Mantapkan Dukungan pada Iqbal-Din...   
37  Menkumham Supratman Teken SK Baru PKB, Duet Ca...   
38  Pengamat: Pilgub Jatim Lebih Dominan Melihat F...   
39  Pilkada Majalengka, Aceng Sunanto Alihkan Duku...   
40  Bacawabup Lathifah Solidkan Seribu Relawan, Si...   
41  Rois Syuriah Sebut Visi Misi Untoro-Wahyudi Se...   
42  Ribuan Kader PKB Kabupaten Mojokerto Panasi Me...   
43  Sejumlah Kader Partai Golkar dan PKB Berbalik ...   
44  Sukiman Azmy Mantapkan Dukungan pada Iqbal-Din...   
45  Menkumham Supratman Teken SK Baru PKB, Duet Ca...   
46  Pengamat: Pilgub Jatim Lebih Dominan Melihat F...   
47  Pilkada Majalengka, Aceng Sunanto Alihkan Duku...   
48  Bacawabup Lathifah Solidkan Seribu Relawan, Si...   
49  Rois Syuriah Sebut Visi Misi Untoro-Wahyudi Se...   

                                           isi_berita      tanggal_berita  \
0   TIMESINDONESIA, MALANG – Bakal cawabup Malang,...  04/09/2024 - 22:02   
1   TIMESINDONESIA, BANTUL – Rois Syuriah PCNU Ban...  04/09/2024 - 20:54   
2   TIMESINDONESIA, MOJOKERTO – Ribuan kader PKB K...  04/09/2024 - 19:23   
3   TIMESINDONESIA, CILACAP – Sebagian kader dari ...  04/09/2024 - 18:28   
4   TIMESINDONESIA, LOMBOK TIMUR – Bupati Lombok T...  04/09/2024 - 16:43   
5   TIMESINDONESIA, JAKARTA – Rabu (4/9/2024), di ...  04/09/2024 - 16:30   
6   TIMESINDONESIA, SURABAYA – Pasangan Khofifah I...  04/09/2024 - 15:52   
7   TIMESINDONESIA, MAJALENGKA – Keputusan mengeju...  04/09/2024 - 15:16   
8   TIMESINDONESIA, MALANG – Bakal cawabup Malang,...  04/09/2024 - 22:02   
9   TIMESINDONESIA, BANTUL – Rois Syuriah PCNU Ban...  04/09/2024 - 20:54   
10  TIMESINDONESIA, MOJOKERTO – Ribuan kader PKB K...  04/09/2024 - 19:23   
11  TIMESINDONESIA, CILACAP – Sebagian kader dari ...  04/09/2024 - 18:28   
12  TIMESINDONESIA, LOMBOK TIMUR – Bupati Lombok T...  04/09/2024 - 16:43   
13  TIMESINDONESIA, JAKARTA – Rabu (4/9/2024), di ...  04/09/2024 - 16:30   
14  TIMESINDONESIA, SURABAYA – Pasangan Khofifah I...  04/09/2024 - 15:52   
15  TIMESINDONESIA, MAJALENGKA – Keputusan mengeju...  04/09/2024 - 15:16   
16  TIMESINDONESIA, MALANG – Bakal cawabup Malang,...  04/09/2024 - 22:02   
17  TIMESINDONESIA, BANTUL – Rois Syuriah PCNU Ban...  04/09/2024 - 20:54   
18  TIMESINDONESIA, MOJOKERTO – Ribuan kader PKB K...  04/09/2024 - 19:23   
19  TIMESINDONESIA, CILACAP – Sebagian kader dari ...  04/09/2024 - 18:28   
20  TIMESINDONESIA, LOMBOK TIMUR – Bupati Lombok T...  04/09/2024 - 16:43   
21  TIMESINDONESIA, JAKARTA – Rabu (4/9/2024), di ...  04/09/2024 - 16:30   
22  TIMESINDONESIA, SURABAYA – Pasangan Khofifah I...  04/09/2024 - 15:52   
23  TIMESINDONESIA, MAJALENGKA – Keputusan mengeju...  04/09/2024 - 15:16   
24  TIMESINDONESIA, MALANG – Bakal cawabup Malang,...  04/09/2024 - 22:02   
25  TIMESINDONESIA, BANTUL – Rois Syuriah PCNU Ban...  04/09/2024 - 20:54   
26  TIMESINDONESIA, MOJOKERTO – Ribuan kader PKB K...  04/09/2024 - 19:23   
27  TIMESINDONESIA, CILACAP – Sebagian kader dari ...  04/09/2024 - 18:28   
28  TIMESINDONESIA, LOMBOK TIMUR – Bupati Lombok T...  04/09/2024 - 16:43   
29  TIMESINDONESIA, JAKARTA – Rabu (4/9/2024), di ...  04/09/2024 - 16:30   
30  TIMESINDONESIA, SURABAYA – Pasangan Khofifah I...  04/09/2024 - 15:52   
31  TIMESINDONESIA, MAJALENGKA – Keputusan mengeju...  04/09/2024 - 15:16   
32  TIMESINDONESIA, MALANG – Bakal cawabup Malang,...  04/09/2024 - 22:02   
33  TIMESINDONESIA, BANTUL – Rois Syuriah PCNU Ban...  04/09/2024 - 20:54   
34  TIMESINDONESIA, MOJOKERTO – Ribuan kader PKB K...  04/09/2024 - 19:23   
35  TIMESINDONESIA, CILACAP – Sebagian kader dari ...  04/09/2024 - 18:28   
36  TIMESINDONESIA, LOMBOK TIMUR – Bupati Lombok T...  04/09/2024 - 16:43   
37  TIMESINDONESIA, JAKARTA – Rabu (4/9/2024), di ...  04/09/2024 - 16:30   
38  TIMESINDONESIA, SURABAYA – Pasangan Khofifah I...  04/09/2024 - 15:52   
39  TIMESINDONESIA, MAJALENGKA – Keputusan mengeju...  04/09/2024 - 15:16   
40  TIMESINDONESIA, MALANG – Bakal cawabup Malang,...  04/09/2024 - 22:02   
41  TIMESINDONESIA, BANTUL – Rois Syuriah PCNU Ban...  04/09/2024 - 20:54   
42  TIMESINDONESIA, MOJOKERTO – Ribuan kader PKB K...  04/09/2024 - 19:23   
43  TIMESINDONESIA, CILACAP – Sebagian kader dari ...  04/09/2024 - 18:28   
44  TIMESINDONESIA, LOMBOK TIMUR – Bupati Lombok T...  04/09/2024 - 16:43   
45  TIMESINDONESIA, JAKARTA – Rabu (4/9/2024), di ...  04/09/2024 - 16:30   
46  TIMESINDONESIA, SURABAYA – Pasangan Khofifah I...  04/09/2024 - 15:52   
47  TIMESINDONESIA, MAJALENGKA – Keputusan mengeju...  04/09/2024 - 15:16   
48  TIMESINDONESIA, MALANG – Bakal cawabup Malang,...  04/09/2024 - 22:02   
49  TIMESINDONESIA, BANTUL – Rois Syuriah PCNU Ban...  04/09/2024 - 20:54   

   kategori_berita  
0          Politik  
1          Politik  
2          Politik  
3          Politik  
4          Politik  
5          Politik  
6          Politik  
7          Politik  
8          Politik  
9          Politik  
10         Politik  
11         Politik  
12         Politik  
13         Politik  
14         Politik  
15         Politik  
16         Politik  
17         Politik  
18         Politik  
19         Politik  
20         Politik  
21         Politik  
22         Politik  
23         Politik  
24         Politik  
25         Politik  
26         Politik  
27         Politik  
28         Politik  
29         Politik  
30         Politik  
31         Politik  
32         Politik  
33         Politik  
34         Politik  
35         Politik  
36         Politik  
37         Politik  
38         Politik  
39         Politik  
40         Politik  
41         Politik  
42         Politik  
43         Politik  
44         Politik  
45         Politik  
46         Politik  
47         Politik  
48         Politik  
49         Politik  
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="markdown.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Markdown Files</p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#konsep-crawling-data">Konsep Crawling Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#teknik-dan-cara-crawling-menggunakan-python">Teknik dan Cara Crawling Menggunakan Python</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tools-yang-digunakan-lybrary">Tools yang Digunakan (Lybrary)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#code-crawling-berita-online">Code Crawling Berita Online</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book Community
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>